nohup: ignoring input
Importing module 'gym_38' (/home/wutr/IsaacGym/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/wutr/IsaacGym/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
PyTorch version 2.3.1
Device count 3
/home/wutr/IsaacGym/isaacgym/python/isaacgym/_bindings/src/gymtorch
Using /home/wutr/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Emitting ninja build file /home/wutr/.cache/torch_extensions/py38_cu121/gymtorch/build.ninja...
Building extension module gymtorch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module gymtorch...
Setting seed: 1
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:1
GPU Pipeline: enabled
Actor MLP: Sequential(
  (0): Linear(in_features=45, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=12, bias=True)
)
Critic MLP: Sequential(
  (0): Linear(in_features=45, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=1, bias=True)
)
Loading low-level policy checkpoint: /home/wutr/IsaacGym/legged_gym_go2/logs/rough_go2/Sep08_11-57-26_/model_18500.pt
Actor MLP: Sequential(
  (0): Linear(in_features=40, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=512, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=512, out_features=512, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=512, out_features=512, bias=True)
  (7): ELU(alpha=1.0)
  (8): Linear(in_features=512, out_features=3, bias=True)
)
Critic MLP: Sequential(
  (0): Linear(in_features=40, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=512, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=512, out_features=512, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=512, out_features=512, bias=True)
  (7): ELU(alpha=1.0)
  (8): Linear(in_features=512, out_features=1, bias=True)
)
resuming from checkpoint: /home/wutr/IsaacGym/logs/high_level_go2/20251125-141002/model_1300.pt
  continuing from iteration 1300
  previous checkpoints were in: /home/wutr/IsaacGym/logs/high_level_go2/20251125-141002
  new checkpoints will be saved to: logs/high_level_go2/20251126-082212
Reach-Avoid training
  envs       : 4096
  obs dim    : 40
  action dim : 3
  horizon    : 300
  device     : cuda:1
  log dir    : logs/high_level_go2/20251126-082212
iter 01301 | success 0.663 | policy_loss 0.00089 | value_loss 1659.81423 | Vmean -201.636 | Rmean -208.771 | Vrmse 55.910 | VexpVar 0.858 | adv_std 55.453 | elapsed 51.52s
iter 01302 | success 0.667 | policy_loss 0.00011 | value_loss 1610.59194 | Vmean -197.374 | Rmean -207.334 | Vrmse 55.979 | VexpVar 0.862 | adv_std 55.086 | elapsed 49.09s
iter 01303 | success 0.674 | policy_loss -0.00004 | value_loss 1553.56007 | Vmean -196.677 | Rmean -206.543 | Vrmse 55.000 | VexpVar 0.871 | adv_std 54.108 | elapsed 47.36s
iter 01304 | success 0.675 | policy_loss 0.00018 | value_loss 1604.74307 | Vmean -195.510 | Rmean -205.782 | Vrmse 55.805 | VexpVar 0.866 | adv_std 54.852 | elapsed 48.25s
iter 01305 | success 0.674 | policy_loss 0.00440 | value_loss 1616.21440 | Vmean -198.170 | Rmean -207.948 | Vrmse 55.475 | VexpVar 0.865 | adv_std 54.607 | elapsed 48.01s
iter 01306 | success 0.678 | policy_loss 0.00266 | value_loss 1612.73375 | Vmean -202.776 | Rmean -209.436 | Vrmse 55.266 | VexpVar 0.865 | adv_std 54.863 | elapsed 47.38s
iter 01307 | success 0.667 | policy_loss 0.00204 | value_loss 1640.27211 | Vmean -207.423 | Rmean -212.367 | Vrmse 55.741 | VexpVar 0.858 | adv_std 55.521 | elapsed 48.42s
iter 01308 | success 0.663 | policy_loss 0.00229 | value_loss 1691.28645 | Vmean -208.606 | Rmean -211.995 | Vrmse 56.323 | VexpVar 0.855 | adv_std 56.221 | elapsed 51.58s
iter 01309 | success 0.686 | policy_loss 0.00518 | value_loss 1599.91941 | Vmean -204.091 | Rmean -212.271 | Vrmse 55.508 | VexpVar 0.858 | adv_std 54.902 | elapsed 50.99s
iter 01310 | success 0.678 | policy_loss 0.00309 | value_loss 1662.49330 | Vmean -204.801 | Rmean -211.702 | Vrmse 55.659 | VexpVar 0.861 | adv_std 55.229 | elapsed 49.51s
  saved checkpoint: logs/high_level_go2/20251126-082212/model_1310.pt
iter 01311 | success 0.669 | policy_loss 0.00017 | value_loss 1621.06803 | Vmean -204.145 | Rmean -210.799 | Vrmse 56.002 | VexpVar 0.859 | adv_std 55.605 | elapsed 51.83s
iter 01312 | success 0.676 | policy_loss 0.00019 | value_loss 1614.20512 | Vmean -201.775 | Rmean -210.546 | Vrmse 56.012 | VexpVar 0.861 | adv_std 55.321 | elapsed 52.57s
iter 01313 | success 0.667 | policy_loss 0.00010 | value_loss 1597.35729 | Vmean -203.235 | Rmean -211.729 | Vrmse 55.561 | VexpVar 0.860 | adv_std 54.908 | elapsed 53.95s
iter 01314 | success 0.663 | policy_loss 0.00074 | value_loss 1620.11980 | Vmean -201.218 | Rmean -209.856 | Vrmse 56.117 | VexpVar 0.861 | adv_std 55.448 | elapsed 57.98s
iter 01315 | success 0.660 | policy_loss 0.00272 | value_loss 1598.68277 | Vmean -204.292 | Rmean -211.386 | Vrmse 55.766 | VexpVar 0.860 | adv_std 55.313 | elapsed 57.11s
iter 01316 | success 0.669 | policy_loss 0.00101 | value_loss 1616.50746 | Vmean -202.405 | Rmean -209.613 | Vrmse 55.633 | VexpVar 0.860 | adv_std 55.164 | elapsed 51.65s
iter 01317 | success 0.674 | policy_loss 0.00013 | value_loss 1618.07313 | Vmean -204.034 | Rmean -210.766 | Vrmse 56.116 | VexpVar 0.857 | adv_std 55.710 | elapsed 51.73s
iter 01318 | success 0.673 | policy_loss 0.00022 | value_loss 1647.32733 | Vmean -207.791 | Rmean -212.759 | Vrmse 55.438 | VexpVar 0.856 | adv_std 55.215 | elapsed 54.39s
iter 01319 | success 0.682 | policy_loss 0.00001 | value_loss 1646.41457 | Vmean -206.729 | Rmean -212.118 | Vrmse 56.127 | VexpVar 0.854 | adv_std 55.867 | elapsed 58.43s
iter 01320 | success 0.675 | policy_loss -0.00006 | value_loss 1608.36332 | Vmean -207.283 | Rmean -213.062 | Vrmse 55.702 | VexpVar 0.855 | adv_std 55.401 | elapsed 59.90s
  saved checkpoint: logs/high_level_go2/20251126-082212/model_1320.pt
